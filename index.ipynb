{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Columns Lab\n",
    "\n",
    "## CRUD Operations with DataFrame Columns\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "In this lab, we'll learn how to create, read, update, and delete rows and columns with pandas dataframes!\n",
    "\n",
    "### Objectives\n",
    "\n",
    "* Access, update, add, and remove columnar data from a DataFrame\n",
    "* Access, update, add, and remove row data from a DataFrame\n",
    "* Enumerate over rows using built-in pandas methods\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "In this tutorial, we'll continue working with the _Titanic Survivors_ dataset. \n",
    "\n",
    "### Review--Reading in data from .csv files\n",
    "\n",
    "Before we can begin this lab, we'll need to import all the necessary libraries, as well as read in the data from `titanic.csv` and store it in a DataFrame. \n",
    "\n",
    "**_In the cell below:_**\n",
    "* Import `pandas` as `pd`\n",
    "* Import `numpy` as `np`\n",
    "* Import `matplotlib.pyplot` as `plt`\n",
    "* Run `%matplotlib inline` to make sure any plots we create display inside the notebook correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to read in the data from `titanic.csv`.  Recall that pandas (which we have aliased as `pd`) contains a helper function called `read_csv()`.  This function takes the path of the .csv file to be read in and returns a DataFrame containing the data.\n",
    "\n",
    "in the cell below, read in the data stored in `titanic.csv`, and display the head to make sure everything worked correctly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can get started.\n",
    "\n",
    "### Accessing Columnar Data\n",
    "\n",
    "Recall that in pandas, data is stored natively in column format, with each column stored in its own pandas `Series` object.  The index of the data in the series corresponds to the row it belongs to--the first item in each column series makes up the first row of data, the second item in each column makes up the second row, and so on. \n",
    "\n",
    "One of the most common operations when working with data is to access an entire column of data.  We can slice the column (or columns) we want from a dataframe with the same slicing operator we would use to slice data from a basic list in python.  However, since our columns have string names as indexes rather than numbers, the easiest way to accomplish this is to pass in the name of the column to the slicing operator.  \n",
    "\n",
    "For instance, if we wanted to access the `PassengerId` column, we would type:\n",
    "\n",
    "```python\n",
    "passenger_id_col = df['PassengerId']\n",
    "```\n",
    "\n",
    "As with any string in python, the operation is case-sensitive.  If you get an error, always double-check that you spelled the column name correctly. \n",
    "\n",
    "In the cell below, slice the `Name` column and store it in the variable `name_col`.  Then, display `name_col.head()` to double check that it worked correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Expected Output:_**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0                              Braund, Mr. Owen Harris\n",
    "1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
    "2                               Heikkinen, Miss. Laina\n",
    "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
    "4                             Allen, Mr. William Henry\n",
    "Name: Name, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Multiple Columns\n",
    "\n",
    "We can also easily slice multiple columns in pandas.  This is accomplished by passing in an array containing multiple column names. Whereas slicing a single column returns a pandas series, slicing multiple columns will return another pandas dataframe containing the desired columns.  \n",
    "\n",
    "For instance, the syntax for retrieving a dataframe containing name and passenger ID would be:\n",
    "\n",
    "```python\n",
    "name_and_id_df = df[['Name', 'PassengerId']]\n",
    "```\n",
    "\n",
    "**_Note:_** A common mistake when slicing multiple columns is to forget to wrap the column names in an array.  The entire array is passed in as the first argument for the slicing operator.  If the column names are not wrapped in an array, then each string is seen as a different argument, which pandas does not know how to interpret, and will cause an error. \n",
    "\n",
    "A good habit is to store the names of the columns you want to access as a list in a (well-named) variable, and then pass that variable in to the slicing operator.  This is cleaner, easier to maintain, and helps us avoid a common error.  \n",
    "\n",
    "In the cell below, slice these columns by passing `col_names` into the slicing operator on `df`.  Store the dataframe returned in `multiple_cols_df`, then display the `.head()` of `multiple_cols_df` to ensure that everything worked properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Name', 'Sex', 'Survived']\n",
    "mulitple_cols_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and Removing Columns\n",
    "\n",
    "Another common operation when working with dataframes is adding and removing columns. There are a number of ways to accomplish this, depending on what you would like the column to contain.  The syntax is generally similar to adding a new key-value pair to a python dictionary.  \n",
    "\n",
    "#### Scalar Values\n",
    "\n",
    "If you would like to add a single scalar value (an integer or float) in a column, and that value is the same for every row, you can set the column name equal to the scalar value you would like to add, and this will automatically be turn into a pandas series containing a copy of that value for every row in the dataframe.  This is because pandas is powered by numpy under the hood, which is capable of **_broadcasting_** a scalar value into a vector of the appropriate size before adding it to the DataFrame.  \n",
    "\n",
    "In the cell below, create a column called 'Example 1' that contains the scalar value `3` for every observation. Display the head of the dataframe to ensure that it worked correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Example 1'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computed Values\n",
    "\n",
    "Another common operation is adding a column that contains a value based on the contents of other columns in the row. In Data Science, this is often referred to as **_Feature Engineering_**, where we engineer a new feature based on information already contained within the dataset.\n",
    "\n",
    "For instance, if we wanted to add a new column that contained the result of `'Fare'` divided by `Pclass` for each row, we would type:\n",
    "\n",
    "```python\n",
    "df['Pclass x Fare'] = df['Fare'] x df['Pclass']\n",
    "``` \n",
    "\n",
    "In the cell below, create a new column called `Example 2` and set it equal to the `Age` column multipled by the `Fare` column. Then, call `.head()` on the dataframe to confirm this worked correctly.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Example 2'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Existing Arrays to DataFrames\n",
    "\n",
    "Perhaps the simplest way to add a column is when we already have the column we want to add stored as an array in a preexisting variable.  The one caveat here is that the length of the array we want to add must match the number of rows in the DataFrame! For instance, if our DataFrame contains 100 rows, we can only add an array as a new column if that contains 100 items--any other number will cause the interpreter to throw an error.   \n",
    "\n",
    "In the cell below, we have created an array containing random values that is the same length as the dataframe.  Create a new column called `Example 3` and set it equal to this variable.  As always, display the head to inspect the dataframe and ensure that it worked correctly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vals = np.random.randint(0, 100, size=len(df))\n",
    "df['Example 3'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting a Column at a Specific Index\n",
    "\n",
    "By default, pandas will always insert new columns at the end of the dataframe.  However, sometimes, you may want to insert a column at a different location.  The `DataFrame` class comes prepackaged with a specific method for just this sort of task--`DataFrame.insert()`.  The [insert method](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.insert.html) expects three arguments:\n",
    "\n",
    "**_loc_**: The index at which you would like this new column inserted.  This value must be between 0 (the numeric index of the first column in the DataFrame) and the number of columns in the DataFrame.  \n",
    "\n",
    "**_column_**: The name of the column.  Usually, this will be a string, but it can also be a number (or any hashable object).\n",
    "\n",
    "**_value_**: The array of data that you would like to insert as a column at the given location.\n",
    "\n",
    "Note that this method does not allow duplicate columns to be added to the same dataframe by default, so running it multiple times will throw an error.  \n",
    "\n",
    "In the cell below, reuse the the code from the previous cell to generate another vector of random values.  Store this vector in the variable `Example 4`.  Then, use the `df` object's `.insert()` method to insert this as the third column in the DataFrame, in between `Survived` and `Pclass`.  Name the column `Random Values 2`.  Make sure to call the `.head()` method afterwards to double check that it worked correctly!\n",
    "\n",
    "**_Hint_**: Remember that in python, we start counting at 0, not 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vals_2 = np.random.randint(0, 100, size=len(df))\n",
    "# Use the insert method below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Column Values\n",
    "\n",
    "If you're getting the hang of how things work in pandas, you can probably guess at the proper way to update values in a column. \n",
    "\n",
    "Updating the values for a column works the same as updating the value for any variable in python.  If we wanted to add 5 to every value in the `Fare` column, we use the same basic python syntax as if we were updating a single value stored in a variable:\n",
    "\n",
    "```python\n",
    "df['Fare'] = df['Fare'] + 5\n",
    "```\n",
    "\n",
    "Alternatively, we could also make use of the `+=` operator to accomplish the same goal:\n",
    "\n",
    "```python\n",
    "df['Fare'] += 5\n",
    "```\n",
    "\n",
    "In the cell below, subtract 1 from every value in the `Example 3` column.  Display the head of the DataFrame to ensure this worked correctly.\n",
    "\n",
    "**_NOTE:_** This is an operation that mutates the dataframe each time you run it--if you run the cell multiple times, it will subtract 1 from the current value each time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract one from Example 3 Column below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns \n",
    "\n",
    "The final operation we'll cover in this lab is how to drop columns.  This is also a common operation, and one that's easy to mess up if not done correctly. \n",
    "\n",
    "It's very common to remove DataFrames, so that the data only contains information that will be useful during the modeling steps.  Perhaps a column is mostly null values, or just contains information that isn't useful to our task (e.g. the `Name` or `Cabin` columns in this dataset).  \n",
    "\n",
    "Since this is a common operation, the DataFrame class comes with a built-in method for removing columns (and rows), `DataFrame.drop()`. There are many different optional arguments that this method can take--for a full list, we take a look at the [documentation for this method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html).  However, there are three main arguments you'll want to know well, because you'll want to use them every time: \n",
    "\n",
    "**_labels_**: This is the first positional argument. If you want to drop a single column, this should be the name of that column as a string.  If you want to drop multiple columns, this should be an array containing the string names of each of the columns to drop.  \n",
    "\n",
    "**_axis_**: This tells the dataframe whether the labels you specified correspond to rows or columns. To drop columns, set `axis=1`.  By default, this is set to `axis=0`, which means that if you do not specify that `axis=1`, it will automatically assume that the value(s) passed in for the `labels` argument correspond to row indices.\n",
    "\n",
    "**_inplace_**: This is an optional argument that is set to `False` by default, but it is strongly recommended to specify it each time, even if you want to keep the value set to `False`.  If `False`, this method will return a new DataFrame that is a copy of the old one, but with the specified columns removed.  This means that you will need to store the new DataFrame object this method returns in a variable (either a new one, or overwrite the current one). If set to `inplace=True`, it will mutate the current DataFrame, removing the columns specified in the `labels` argument (or rows, if `axis=0`).\n",
    "\n",
    "If we wanted to drop the `random_vals` column from `df` in place, we would use:\n",
    "\n",
    "```python\n",
    "df.drop('random_vals', axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "**_Note_**: If we ran a cell containing this line of code twice, it would throw an error the second time.  This is because after the first time, this column has been removed from the DataFrame, so the second time it is run, it will throw an error because the DataFrame doesn't contain a column with this name!\n",
    "\n",
    "**_Best Practice:_** It is generally a good idea to set `inplace=False`, and store the dataframe returned in a new variable.  This way, if the cell is run multiple times without resetting the kernel, it won't throw an error.  It is also a good idea because you will still have access to the older version of the DataFrame, before those columns are dropped--this is often useful in a number of situations.  Even though `inplace=False` by default, it is still a good idea to specify this argument every time--this makes it easier to read, understand, and debug your code.  \n",
    "\n",
    "In the cell below, create an array that contains the names of all the columns we've created so far.  Then, use this array to drop all of these columns from the dataframe.  Set `inplace` to `False`, and store the results in the variable below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = None\n",
    "back_to_normal_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Rows\n",
    "\n",
    "Sometimes, you'll need to add a row to a DataFrame. The easiest way to do this is to use the `.loc[]` method and set the value for the row.  By default, the easiest way to do this is to create a dictionary of key-value pairs where all the keys are the column names for the DataFrame, and all the values are the values for the row you will add.  The value must either be a dictionary, or a pandas Series.  You will need to specify the index value to add the new row at inside the `.loc[]` call--if you want to add the row to the end of the dataframe, set this to the length of the DataFrame object.  \n",
    "\n",
    "Remember: any row you add must have the same characteristics as the other rows in the DataFrame--specifically, a value for every column, with each value matching the appropriate data type for that column.  \n",
    "\n",
    "In the cell below, add rows for each of the following passengers to `back_to_normal_df`.  \n",
    "\n",
    "| PassengerId | Survived | Pclass |     Name     |  Sex | Age | SibSp | Parch | Ticket |  Fare | Cabin | Embarked |\n",
    "|:-----------:|:--------:|:------:|:------------:|:----:|:---:|:-----:|:-----:|:------:|:-----:|:-----:|:--------:|\n",
    "|     892     |     1    |    1   |  Adam Enbar  | male | NaN |   0   |   0   | 997604 | 47.45 |  NaN  |     S    |\n",
    "|     893     |     1    |    1   | Avi Flombaum | male | NaN |   0   |   0   | 879253 | 52.15 |  NaN  |     Q    |\n",
    "\n",
    "After you've added them, display the tail of `back_to_normal_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = None\n",
    "\n",
    "avi = None\n",
    "\n",
    "# Use loc to add in rows for adam and avi at the end of back_to_normal_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Rows\n",
    "\n",
    "There are two simple ways to update values for a row.  The first is to overwrite the row itself, and change only the data that you want to change.\n",
    "\n",
    "The other way is to access the row data, and the access and overwrite the index for the cell that you wish to change.  \n",
    "\n",
    "In the cell below, use `.iloc[]` to access the `Cabin` cell for Adam and update the value to contain `'Door'`.  Also update the `Cabin` cell for Avi to contain `'Life Boat'`.\n",
    "\n",
    "If you run into trouble, take a look at the [documentation on selecting and indexing](https://pandas.pydata.org/pandas-docs/stable/indexing.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use iloc to access and update the cells at the appropriate row/column intersections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows\n",
    "\n",
    "We can drop rows the same way we drop columns, using the DataFrame's built-in method for this task.  \n",
    "\n",
    "In the cell below, use the `.drop()` method to remove Avi and Adam's rows by index.  Remember to set `axis=0` since we are dropping rows, not columns. Store the dataframe returned in the `final_df` variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this lab, we learned how to:\n",
    "\n",
    "* Access row/columnar data from a DataFrame\n",
    "* Access, add, remove, and update columnar data from a DataFrame\n",
    "* Access, add, remove, and update row data from a DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
